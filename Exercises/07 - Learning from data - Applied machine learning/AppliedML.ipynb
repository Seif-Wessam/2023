{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All you need is love… And a pet!\n",
    "\n",
    "<img src=\"img/dataset-cover.jpg\" width=\"920\">\n",
    "\n",
    "Here we are going to build a classifier to predict whether an animal from an animal shelter will be adopted or not (aac_intakes_outcomes.csv, available at: https://www.kaggle.com/aaronschlegel/austin-animal-center-shelter-intakes-and-outcomes/version/1#aac_intakes_outcomes.csv). You will be working with the following features:\n",
    "\n",
    "1. *animal_type:* Type of animal. May be one of 'cat', 'dog', 'bird', etc.\n",
    "2. *intake_year:* Year of intake\n",
    "3. *intake_condition:* The intake condition of the animal. Can be one of 'normal', 'injured', 'sick', etc.\n",
    "4. *intake_number:* The intake number denoting the number of occurrences the animal has been brought into the shelter. Values higher than 1 indicate the animal has been taken into the shelter on more than one occasion.\n",
    "5. *intake_type:* The type of intake, for example, 'stray', 'owner surrender', etc.\n",
    "6. *sex_upon_intake:* The gender of the animal and if it has been spayed or neutered at the time of intake\n",
    "7. *age_upon\\_intake_(years):* The age of the animal upon intake represented in years\n",
    "8. *time_in_shelter_days:* Numeric value denoting the number of days the animal remained at the shelter from intake to outcome.\n",
    "9. *sex_upon_outcome:* The gender of the animal and if it has been spayed or neutered at time of outcome\n",
    "10. *age_upon\\_outcome_(years):* The age of the animal upon outcome represented in years\n",
    "11. *outcome_type:* The outcome type. Can be one of ‘adopted’, ‘transferred’, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from itertools import combinations \n",
    "import ast\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sn\n",
    "%matplotlib inline\n",
    "\n",
    "data_folder = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Load the dataset and convert categorical features to a suitable numerical representation (use dummy-variable encoding). \n",
    "- Split the data into a training set (80%) and a test set (20%). Pair each feature vector with the corresponding label, i.e., whether the outcome_type is adoption or not. \n",
    "- Standardize the values of each feature in the data to have mean 0 and variance 1.\n",
    "\n",
    "The use of external libraries is not permitted in part A, except for numpy and pandas. \n",
    "You can drop entries with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15935,)\n"
     ]
    }
   ],
   "source": [
    "columns = ['animal_type', 'intake_year', 'intake_condition', 'intake_number', 'intake_type', 'sex_upon_intake', \\\n",
    "          'age_upon_intake_(years)', 'time_in_shelter_days', 'sex_upon_outcome', 'age_upon_outcome_(years)', \\\n",
    "          'outcome_type']\n",
    "original_data = pd.read_csv(data_folder+'aac_intakes_outcomes.csv', usecols=columns)\n",
    "\n",
    "original_data.dropna()\n",
    "y = original_data['outcome_type']\n",
    "y = np.where(1, y=='Adoption', 0) #3shan teb2a 3aref myn ehh!!!!\n",
    "y = pd.DataFrame(y)\n",
    "\n",
    "\n",
    "X = original_data.copy()\n",
    "X.drop('outcome_type', axis=1, inplace=True) #mohemma awy inplace=True!!!!!\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "np.random.seed(42)\n",
    "shuffled_indices = np.random.permutation(len(X))\n",
    "X_shuffled = X.iloc[shuffled_indices, :]#3shan te3raf te5tar elshuffled indices!!!\n",
    "y_shuffled = y.iloc[shuffled_indices] #mafysh clumns la2en howa aslan column wa7ed!!!\n",
    "\n",
    "split_index = int(0.8*len(X_shuffled))#3shan te3raf hato2af fein w hatebda2 fein!!!\n",
    "X_train = X_shuffled.iloc[:split_index, :]\n",
    "y_train = y_shuffled.iloc[:split_index]\n",
    "y_train = np.array(y_train).ravel()\n",
    "\n",
    "X_train = (X_train-np.mean(X_train, axis = 0))/np.std(X_train, axis = 0)\n",
    "\n",
    "X_test = X_shuffled.iloc[split_index:, :]\n",
    "y_test = y_shuffled.iloc[split_index:]\n",
    "y_test = np.array(y_test).ravel()\n",
    "print(y_test.shape)\n",
    "\n",
    "X_test = (X_test-np.mean(X_test, axis = 0))/np.std(X_test, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Train a logistic regression classifier on your training set. Logistic regression returns probabilities as predictions, so in order to arrive at a binary prediction, you need to put a threshold on the predicted probabilities. \n",
    "- For the decision threshold of 0.5, present the performance of your classifier on the test set by displaying the confusion matrix. Based on the confusion matrix, manually calculate accuracy, precision, recall, and F1-score with respect to the positive and the negative class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7577 1574]\n",
      " [1225 5559]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_test_pred = log_reg.predict(X_test)\n",
    "confusion_matrix_result = confusion_matrix(y_test, y_test_pred)\n",
    "print(confusion_matrix_result) #tn, fp, fn, tp !!!\n",
    "#cm = confusion_matrix(y_test, predictions, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix_result)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8243489174772514 0.7793354829664938 0.8194280660377359 0.7988790687648201\n"
     ]
    }
   ],
   "source": [
    "accuracy = (confusion_matrix_result[0, 0]+confusion_matrix_result[1, 1])/confusion_matrix_result.sum()\n",
    "precision = confusion_matrix_result[1, 1]/(confusion_matrix_result[0, 1]+confusion_matrix_result[1, 1])\n",
    "recall = confusion_matrix_result[1, 1]/(confusion_matrix_result[1, 0]+confusion_matrix_result[1, 1])\n",
    "F1_score = (2*precision*recall/(precision+recall))\n",
    "print(accuracy, precision, recall, F1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) Vary the value of the threshold in the range from 0 to 1 and visualize the value of accuracy, precision, recall, and F1-score (with respect to both classes) as a function of the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_47780/2461098774.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mlog_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mlog_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0my_test_pred_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 )\n\u001b[1;32m   1151\u001b[0m             ):\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0mn_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n\u001b[0m\u001b[1;32m   1304\u001b[0m             path_func(\n\u001b[1;32m   1305\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         )\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             ]\n\u001b[0;32m--> 452\u001b[0;31m             opt_res = optimize.minimize(\n\u001b[0m\u001b[1;32m    453\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m                 \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    679\u001b[0m                                  **options)\n\u001b[1;32m    680\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m         res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    682\u001b[0m                                callback=callback, **options)\n\u001b[1;32m    683\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/scipy/optimize/_lbfgsb_py.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0;31m# Make sure the function returns a true scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/scipy/optimize/_optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/scipy/optimize/_optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_linear_loss.py\u001b[0m in \u001b[0;36mloss_gradient\u001b[0;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mgrad_pointwise\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml2_reg_strength\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m                 \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_pointwise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_dof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"F\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[0m\u001b[1;32m     48\u001b[0m          initial=_NoValue, where=True):\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "threshold = np.linspace(0, 1, 100)\n",
    "print(threshold==0.5)\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "acc_vect = []\n",
    "prec_vect = []\n",
    "recall_vect=[]\n",
    "F1_score_vect = []\n",
    "for t in threshold:\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(X_train, y_train)\n",
    "\n",
    "    y_test_pred_prob = log_reg.predict_proba(X_test) \n",
    "    #print(y_test_pred_prob)\n",
    "    y_test_pred = (np.amax(y_test_pred_prob, axis=1) > t).astype(int)\n",
    "    y_test_pred = pd.DataFrame(y_test_pred)\n",
    "    #print(y_test_pred)\n",
    "    confusion_matrix_result = confusion_matrix(y_test, y_test_pred)\n",
    "    if t == 0.5:\n",
    "        print(confusion_matrix_result)\n",
    "    accuracy = (confusion_matrix_result[0, 0]+confusion_matrix_result[1, 1])/confusion_matrix_result.sum()\n",
    "    acc_vect.append(accuracy)\n",
    "    precision = confusion_matrix_result[1, 1]/(confusion_matrix_result[0, 1]+confusion_matrix_result[1, 1])\n",
    "    prec_vect.append(precision)\n",
    "    recall = confusion_matrix_result[1, 1]/(confusion_matrix_result[1, 0]+confusion_matrix_result[1, 1])\n",
    "    recall_vect.append(recall)\n",
    "    F1_score = (2*precision*recall/(precision+recall))\n",
    "    F1_score_vect.append(F1_score)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(threshold, acc_vect)\n",
    "ax.plot(threshold, prec_vect)\n",
    "ax.plot(threshold, recall_vect)\n",
    "ax.plot(threshold, F1_score_vect)\n",
    "ax.legend(['Accuracy', 'Precision', 'Recall', 'F1-score'])\n",
    "ax.set_xlabel('Threshold')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Accuracy, Precision, Recall, F1-score as a function of the classification threshold')\n",
    "ax.tight_layout()\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D) Plot in a bar chart the coefficients of the logistic regression sorted by their contribution to the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#PLT.BARH 3SHAN TEDDY HORIZONTAL BARS!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Question 1: Which of the following metrics is most suitable when you are dealing with unbalanced classes?\n",
    "\n",
    "- a) F1 Score\n",
    "- b) Recall\n",
    "- c) Precision\n",
    "- d) Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: You are working on a binary classification problem. You trained a model on a training dataset and got the following confusion matrix on the test dataset. What is true about the evaluation metrics (rounded to the second decimal point):\n",
    "\n",
    "|            | Pred = NO|Pred=YES|\n",
    "|------------|----------|--------|\n",
    "| Actual NO  |    50    |   10   |\n",
    "| Actual YES |    5     |   100  |\n",
    "\n",
    "- a) Accuracy is 0.95\n",
    "- b) Accuracy is 0.85\n",
    "- c) False positive rate is 0.95\n",
    "- d) True positive rate is 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
